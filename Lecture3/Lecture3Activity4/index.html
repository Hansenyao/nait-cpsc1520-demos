<!DocType html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Week3 - Activity4</title>
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <script src="js/L3activity4.js" defer></script>


</head>

<body>
    <header>
        <h1>Lecture3 - Activity4 - Adding and Removing Classes through JS </h1>
    </header>
    <main>
        <article class="recentWork">
            <p>
                Machine Learning has emerged as a valuable tool for spotting patterns and trends that might otherwise
                escape humans. The technology, which can build elaborate models based on everything from personal
                preferences to facial recognition, is used widely to understand behavior, spot patterns and trends, and
                make informed predictions.
            </p>
            <p> Yet for all the gains, there is also plenty of pain. A major problem associated with machine learning is
                that once an algorithm or model exists, expunging individual records or chunks of data is
                extraordinarily difficult. In most cases, it is necessary to retrain the entire modelâ€”sometimes with no
                assurance that that model will not continue to incorporate the suspect data in some way, says Gautam
                Kamath, an assistant professor in the David R. Cheriton School of Computer Science at the
                University of Waterloo in Canada</p>
        </article>
        <article>
            <p>
                The GDPR (but also most data protection regulations) define some categories of personal data as
                sensitive and prohibits processing them with limited exceptions (for example, the user provides explicit
                consent to process that sensitive data for a specific purpose). In particular, the GDPR defines as
                sensitive personal data as: "data revealing racial or ethnic origin, political opinions, religious or
                philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for
                the purpose of uniquely identifying a natural person, data concerning health or data concerning a
                natural person's sex life or sexual orientation."
            </p>
            <p class="recentWork">
                In a recent work, we demonstrated that Facebook (FB) labels 73% of users within the EU with potentially
                sensitive interests (referred to as ad preferences as well), which may contravene the GDPR. FB assigns
                user's different ad preferences based on their online activity within this social network. Advertisers
                running ad campaigns can target groups of users that have been assigned a particular ad preference (for
                example, target FB users interested in Starbucks).
            </p>

        </article>
        <button id="addClassButton">Add Class To Paragraph </button>
        <button id="removeClassButton">Remove Class From Paragraph</button>
    </main>


    <footer>Created by Oveeyen Moonian on 13 May 2022</footer>


</body>

</html>